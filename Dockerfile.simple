# ================================================================================================
# SIMPLE AI INFERENCE SERVER DOCKERFILE (For Cloud Deployment)
# ================================================================================================
#
# This is a simplified version optimized for cloud platforms like Render, Railway, etc.
# Removes complex CUDA setup that can cause build issues on some platforms.
#
# ================================================================================================

# Use latest Rust image for compatibility
FROM rust:1.80-slim as builder

# Install system dependencies
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy all source files (simplified approach for cloud deployment)
COPY . .

# Build the application (single-stage build for simplicity)
RUN cargo build --release

# ================================================================================================
# RUNTIME STAGE
# ================================================================================================
FROM debian:bookworm-slim as runtime

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create application user
RUN groupadd -r aiserver && useradd -r -g aiserver -u 1000 aiserver

# Create directories
RUN mkdir -p /app/models /app/logs /app/data \
    && chown -R aiserver:aiserver /app

# Set working directory
WORKDIR /app

# Copy the binary from builder stage
COPY --from=builder /app/target/release/ai-interence-server /app/ai-inference-server

# Set permissions
RUN chmod +x /app/ai-inference-server

# Switch to non-root user
USER aiserver

# Environment variables
ENV HOST=0.0.0.0
ENV PORT=3000
ENV MODEL_CACHE_DIR=/app/models
ENV TOKENIZERS_PARALLELISM=false
ENV RAYON_NUM_THREADS=2

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:3000/health || exit 1

# Run the application
CMD ["/app/ai-inference-server"]