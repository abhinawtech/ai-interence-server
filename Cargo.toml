[package]
name = "ai-interence-server"
version = "0.1.0"
edition = "2021"  # COMPATIBILITY: Rust 2021 edition provides stable feature set




[dependencies]
axum = { version = "0.8.4", features = ["macros", "multipart"] }
tokio = { version = "1.0", features = ["full"] }
# OPTIMIZATION: Cross-platform GPU Acceleration Features
# Metal for Apple Silicon, accelerate for optimized CPU operations
# CUDA can be enabled separately with --features cuda if needed
candle-core = { version = "0.9.1", features = ["metal", "accelerate"] }
candle-nn = { version = "0.9.1", features = ["metal", "accelerate"] }
candle-transformers = { version = "0.9.1", features = ["metal", "accelerate"] }
tokenizers = "0.21.4"
# OPTIMIZATION: Dependency Minimization for Faster Compilation
# Removed unused ML libraries to reduce compile time and binary size
# ort = "1.16.3"        # ONNX Runtime - not needed for Candle-based inference
# ndarray = "0.16"      # NumPy-like arrays - Candle provides tensor operations
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
regex = "1.10"
tracing = "0.1"
tracing-subscriber = "0.3"
anyhow = "1.0.99"
uuid = { version = "1.18.0", features = ["v4", "serde"] }
base64 = "0.21"
async-trait = "0.1"
hf-hub = { version = "0.4.3", features = ["tokio"] }
thiserror = "2.0.16"
chrono = { version = "0.4", features = ["serde"] }
tower = { version = "0.5.2", features = ["util"] }
tower-http = { version = "0.6.2", features = ["cors"] }
dotenv = "0.15"
reqwest = { version = "0.12.23", features = ["json"] }
url = "2.5"
toml = "0.9.5"
rand = "0.9.2"
tempfile = "3.21.0"
clap = { version = "4.0", features = ["derive"] }
futures = "0.3"
# QDRANT: Vector Database Dependencies
qdrant-client = "1.15.0"
tonic = "0.14.1"
prost = "0.14.1"
# rayon = "1.10.0"      # CONCURRENCY: Removed to avoid thread pool conflicts
                          # Rayon's work-stealing can interfere with Tokio's async executor
                          # Tokio handles parallelism for I/O, Candle handles compute parallelism


[features]
default = []
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]

# PERFORMANCE: Aggressive Release Optimizations
[profile.release]
opt-level = 3        # Maximum optimization level - enables auto-vectorization
lto = true          # Link-Time Optimization - cross-crate inlining (~10% speedup)
codegen-units = 1   # Single compilation unit - better optimization at cost of compile time
panic = "abort"     # Faster panic handling - no unwinding overhead
strip = true        # Remove debug symbols - smaller binary size

# DEVELOPMENT: Balanced Debug Performance
# Level 1 optimization provides reasonable performance while maintaining debug info
[profile.dev]
opt-level = 1       # Basic optimizations - faster execution without long compile times
