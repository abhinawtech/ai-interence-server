# ================================================================================================
# QDRANT PRODUCTION CONFIGURATION
# ================================================================================================
#
# PURPOSE:
# Production-optimized configuration for Qdrant vector database with performance tuning
# specifically designed for AI embedding workloads and large-scale vector operations.
#
# OPTIMIZATION FOCUS:
# ✅ HNSW indexing parameters for fast similarity search
# ✅ Memory management for large vector collections
# ✅ Performance tuning for AI workloads
# ✅ Storage optimization for persistent data
# ✅ Monitoring and telemetry integration
#
# ================================================================================================

# ================================================================================================
# SERVICE CONFIGURATION
# ================================================================================================
service:
  # Network configuration
  host: "0.0.0.0"
  http_port: 6333
  grpc_port: 6334
  
  # CORS settings for web dashboard and API access
  enable_cors: true
  cors_origins: ["*"]  # Restrict in production environment
  
  # Request handling
  max_request_size_mb: 128    # Increased for batch vector operations
  max_workers: 8              # Optimal for production workloads
  
  # API Security (disable for development, enable in production)
  api_key: ""                 # Set via environment variable
  read_only: false
  
  # Connection limits
  max_concurrent_requests: 1000

# ================================================================================================
# STORAGE CONFIGURATION
# ================================================================================================
storage:
  # Storage paths
  storage_path: "/qdrant/storage"
  snapshots_path: "/qdrant/snapshots"
  temp_path: "/tmp/qdrant"
  
  # ==============================================================================================
  # PERFORMANCE OPTIMIZATION
  # ==============================================================================================
  performance:
    # Thread allocation for search operations
    max_search_threads: 8        # Parallel search execution
    max_optimization_threads: 4  # Background optimization processes
    
    # Indexing thresholds
    indexing_threshold: 50000    # Start indexing after this many vectors
    
    # Memory management
    memory_limit_mb: 0           # 0 = automatic (use available memory)
    
  # ==============================================================================================
  # HNSW INDEX CONFIGURATION (AI-OPTIMIZED)
  # ==============================================================================================
  hnsw:
    # Core HNSW parameters
    m: 64                        # Connectivity (higher = better recall, more memory)
    ef_construct: 1024           # Construction parameter (higher = better quality)
    
    # Search parameters
    full_scan_threshold: 20000   # Use exact search below this collection size
    max_indexing_threads: 8      # Parallel index construction
    
    # Index optimization
    on_disk: false              # Keep index in memory for performance
    
  # ==============================================================================================
  # MEMORY MANAGEMENT
  # ==============================================================================================
  memory:
    # Global HNSW parameters (fallback for collections without specific config)
    global_m: 64
    global_ef_construct: 1024
    global_ef: 512              # Search parameter for all queries
    
    # Memory optimization
    mmap_threshold_kb: 10240    # Use memory mapping for segments > 10MB
    
  # ==============================================================================================
  # WRITE-AHEAD LOG (WAL) CONFIGURATION
  # ==============================================================================================
  wal:
    wal_capacity_mb: 128        # WAL file size (larger = fewer file rotations)
    wal_segments_ahead: 4       # Number of WAL segments to pre-allocate
    
  # ==============================================================================================
  # OPTIMIZER CONFIGURATION
  # ==============================================================================================
  optimizers:
    # Trigger conditions
    deleted_threshold: 0.2      # Optimize when 20% of vectors are deleted
    vacuum_min_vector_number: 5000  # Minimum vectors before vacuum
    
    # Segment management
    default_segment_number: 4   # Initial number of segments per collection
    max_segment_size_mb: 500    # Maximum size per segment
    
    # Memory mapping
    memmap_threshold_mb: 50     # Use memory mapping for segments > 50MB
    indexing_threshold_mb: 100  # Start indexing segments > 100MB
    
    # Optimization timing
    max_optimization_threads: 4
    
    # Flush settings
    flush_interval_sec: 300     # Flush to disk every 5 minutes

# ================================================================================================
# CLUSTER CONFIGURATION
# ================================================================================================
cluster:
  # Enable clustering for production (disable for single-node)
  enabled: true
  
  # Node configuration
  node_id: 1                    # Unique node identifier
  
  # Consensus settings
  consensus_timeout: 1000       # Consensus timeout in milliseconds
  tick_period_ms: 100          # Tick period for consensus
  
  # Inter-node communication
  grpc_timeout_ms: 5000        # gRPC call timeout

# ================================================================================================
# TELEMETRY AND MONITORING
# ================================================================================================
telemetry_disabled: false

# Detailed telemetry configuration
telemetry:
  # Metrics collection
  enabled: true
  
  # Anonymous usage statistics (disable for privacy)
  anonymous_telemetry: false
  
  # Metrics export format
  format: "prometheus"

# ================================================================================================
# LOGGING CONFIGURATION
# ================================================================================================
log_level: "INFO"  # Options: ERROR, WARN, INFO, DEBUG, TRACE

# Structured logging
logging:
  # Log format (json for production, text for development)
  format: "json"
  
  # Log filtering
  filter: "qdrant=info"
  
  # File logging (optional)
  file:
    enabled: false
    path: "/qdrant/logs/qdrant.log"
    max_size_mb: 100
    max_files: 10

# ================================================================================================
# COLLECTION DEFAULTS
# ================================================================================================
collection_defaults:
  # Default vector configuration
  vectors:
    distance: "Cosine"          # Default distance metric
    
  # Default HNSW parameters for new collections
  hnsw_config:
    m: 64
    ef_construct: 1024
    full_scan_threshold: 20000
    
  # Default optimization parameters
  optimizer_config:
    deleted_threshold: 0.2
    vacuum_min_vector_number: 1000
    default_segment_number: 4
    max_segment_size_mb: 500
    
  # Default quantization (for memory optimization)
  quantization_config:
    scalar:
      type: "int8"             # Use int8 quantization for memory efficiency
      quantile: 0.99
      always_ram: true

# ================================================================================================
# ADVANCED CONFIGURATION
# ================================================================================================

# Experimental features (use with caution in production)
experimental:
  # Vector search optimizations
  search_optimizations:
    enable_hnsw_ef_optimization: true
    enable_query_cache: true
    cache_size_mb: 256
    
  # Storage optimizations
  storage_optimizations:
    enable_async_io: true
    io_threads: 4
    
# Runtime limits
limits:
  # Maximum collections per node
  max_collections: 1000
  
  # Maximum vectors per collection
  max_vectors_per_collection: 100000000  # 100M vectors
  
  # Request timeouts
  search_timeout_ms: 30000     # 30 seconds
  insert_timeout_ms: 60000     # 60 seconds
  
# Health check configuration
health:
  startup_timeout_ms: 30000    # 30 seconds for startup
  check_interval_ms: 1000      # Health check every second